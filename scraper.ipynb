{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import brotli\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://fr.indeed.com/emplois?q=data+engineer&l=Paris&radius=10\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9,lt;q=0.8,et;q=0.7,de;q=0.6\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text/html;charset=UTF-8\n",
      "Error decompressing content: BrotliDecompress failed\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({}, columns=[\"title\", \"company\", \"city\", \"min_salary\", \"max_salary\", \"frequency\"])\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "# Détecter l'encodage spécifié dans les headers\n",
    "content_type = resp.headers.get('Content-Type', '')\n",
    "print(content_type)\n",
    "encoding = 'utf-8'  # Encodage par défaut\n",
    "if 'charset=' in content_type:\n",
    "    encoding = content_type.split('charset=')[-1]\n",
    "# Décompresser le contenu si encodé en Brotli\n",
    "if resp.headers.get('Content-Encoding') == 'br':\n",
    "    try:\n",
    "        decompressed_content = brotli.decompress(resp.content)\n",
    "        text = decompressed_content.decode(encoding)\n",
    "    except Exception as e:\n",
    "        print(\"Error decompressing content:\", e)\n",
    "        text = resp.text\n",
    "else:\n",
    "    text = resp.text  # Utiliser la méthode text qui gère automatiquement l'encodage\n",
    "# Parser le contenu HTML avec BeautifulSoup\n",
    "soup = Soup(text, \"html.parser\")\n",
    "\n",
    "contents = soup.find_all(\"li\", {\"class\": \"css-5lfssm eu4oa1w0\"})\n",
    "\n",
    "for element in contents[:-1]:\n",
    "    element_dict={}\n",
    "    head = element.find(\"h2\", {\"class\": \"jobTitle css-198pbd eu4oa1w0\"})\n",
    "    location = element.find(\"div\", {\"class\": \"company_location css-17fky0v e37uo190\"})\n",
    "    if head is not None:\n",
    "        title = head.find(\"span\")[\"title\"]\n",
    "        element_dict[\"title\"] = title\n",
    "    else:\n",
    "        continue\n",
    "    if location is not None:\n",
    "        company_name = location.find(\"span\", {\"data-testid\":\"company-name\" , \"class\": \"css-63koeb eu4oa1w0\"})\n",
    "        if company_name is not None:\n",
    "            element_dict[\"company\"] = company_name.text\n",
    "        city = location.find(\"div\", {\"data-testid\":\"text-location\" , \"class\": \"css-1p0sjhy eu4oa1w0\"})\n",
    "        if city is not None:\n",
    "            element_dict[\"city\"] = city.text\n",
    "    metadata = element.find(\"div\", {\"class\":\"heading6 tapItem-gutter metadataContainer css-z5ecg7 eu4oa1w0\"})\n",
    "    if metadata is not None:\n",
    "        salary_block = metadata.find(\"div\", {\"class\":\"metadata salary-snippet-container css-5zy3wz eu4oa1w0\"})\n",
    "        if salary_block is not None:\n",
    "            salary = salary_block.find(\"div\", {\"data-testid\":\"attribute_snippet_testid\", \"class\":\"css-1cvvo1b eu4oa1w0\"})\n",
    "            boundaries = salary.text.split(\"€\")[:-1]\n",
    "            frequency = salary.text.split(\" \")[-1]\n",
    "            frequency_map = {\"mois\":\"mensuel\", \"an\":\"annuel\"}\n",
    "            element_dict[\"frequency\"] = frequency_map.get(frequency, \"autre\")\n",
    "            for boundary in boundaries:\n",
    "                if \"de\" in boundary.lower():\n",
    "                    element_dict[\"min_salary\"] = \"\".join(filter(str.isdigit, boundary))\n",
    "                elif \"à\" in boundary.lower():\n",
    "                    element_dict[\"max_salary\"] = \"\".join(filter(str.isdigit, boundary))\n",
    "\n",
    "    url_job = \"http://fr.indeed.com\" + element.find(\"a\", {\"class\":\"jcs-JobTitle css-jspxzf eu4oa1w0\"})[\"href\"]\n",
    "    if any(element_dict.values()):\n",
    "        df = pd.concat([df, pd.DataFrame(element_dict, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\", index=False, sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to Timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ctesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:530\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion._convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ctesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:318\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ctesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dateutil\\parser\\_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DEFAULTPARSER\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ctesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dateutil\\parser\\_parser.py:649\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 649\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ctesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dateutil\\parser\\_parser.py:1235\u001b[0m, in \u001b[0;36mparser._build_naive\u001b[1;34m(self, res, default)\u001b[0m\n\u001b[0;32m   1233\u001b[0m         repl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m monthrange(cyear, cmonth)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 1235\u001b[0m naive \u001b[38;5;241m=\u001b[39m default\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrepl)\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mweekday \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\u001b[38;5;241m.\u001b[39mday:\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m soup \u001b[38;5;241m=\u001b[39m Soup(html_content, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m script \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatePublished\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(s)][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatePublished\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\ctesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\tslibs\\timestamps.pyx:1698\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.__new__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ctesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:249\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ctesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:533\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion._convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to Timestamp"
     ]
    }
   ],
   "source": [
    "response = requests.get(url_job, headers=headers)\n",
    "response.raise_for_status()\n",
    "html_content = response.content.decode(\"utf-8\")\n",
    "soup = Soup(html_content, \"html.parser\")\n",
    "script = [s for s in soup.find_all(\"script\") if \"datePublished\" in str(s)][0]\n",
    "print(pd.Timestamp(script.text.split(\"datePublished\")[1].split(\":\")[1].split(\",\")[0].strip().replace('\"', \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "--------------------------------------------------\n",
      "1 1\n",
      "--------------------------------------------------\n",
      "2 1\n",
      "--------------------------------------------------\n",
      "3 1\n",
      "--------------------------------------------------\n",
      "4 1\n",
      "--------------------------------------------------\n",
      "5 1\n",
      "--------------------------------------------------\n",
      "6 1\n",
      "--------------------------------------------------\n",
      "7 1\n",
      "--------------------------------------------------\n",
      "8 1\n",
      "--------------------------------------------------\n",
      "9 1\n",
      "--------------------------------------------------\n",
      "10 1\n",
      "--------------------------------------------------\n",
      "11 1\n",
      "--------------------------------------------------\n",
      "12 1\n",
      "--------------------------------------------------\n",
      "13 1\n",
      "--------------------------------------------------\n",
      "14 1\n",
      "--------------------------------------------------\n",
      "15 1\n",
      "--------------------------------------------------\n",
      "16 1\n",
      "--------------------------------------------------\n",
      "17 3\n",
      "--------------------------------------------------\n",
      "18 1\n",
      "--------------------------------------------------\n",
      "19 1\n",
      "--------------------------------------------------\n",
      "20 1\n",
      "--------------------------------------------------\n",
      "21 1\n",
      "--------------------------------------------------\n",
      "22 1\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, script in enumerate(soup.findAll(\"script\")):\n",
    "    print(i, len(script.text.split(\"datePublished\")))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
